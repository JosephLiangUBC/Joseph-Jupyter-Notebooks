{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook UI to graph your TAP data!\n",
    "\n",
    "Version 1.7 - Joseph Liang, Rankin Lab\n",
    "Updated:\n",
    "1. Upgraded folder path selection application\n",
    "2. Upgraded dataset management (less moving parts for end-user)\n",
    "3. output changed from tif -> png\n",
    "4. Added tap-correction function for missing taps (should be working now)\n",
    "5. Added plate column to evaluate plate-discrepancies\n",
    "6. Added separate graphing function for plate-discrepancies\n",
    "7. Added colour palette-setting function\n",
    "\n",
    "## Known bug: Step 2 an empty windows displays in Mac. May also apply to linux/windows.\n",
    "\n",
    "## Beginner Essentials:\n",
    "1. Shift-Enter to run each cell. After you run, you should see an output \"done step #\". If not, an error has occured\n",
    "2. When inputting your own code/revising the code, make sure you close all your quotation marks '' and brackets (), [], {}.\n",
    "3. Don't leave any commas (,) hanging! (make sure an object always follows a comma. If there is nothing after a comma, remove the comma!\n",
    "4. Learning to code? Each line of code is annotated to help you understand how this code works!\n",
    "\n",
    "## 3. Run all cells/steps sequentially, even the ones that do not need input\n",
    "\n",
    "## Steps that require input: #3, #6.1, #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is for Tap-Habituation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Packages Required (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #<- package used to import and organize data\n",
    "import numpy as np #<- package used to import and organize data\n",
    "import math\n",
    "import os #<- package used to work with system file paths\n",
    "import seaborn as sns #<- package used to plot graphs\n",
    "from matplotlib import pyplot as plt #<- another package used to plot graphs\n",
    "from itertools import cycle #<- package used to iterate down rows (used in step 5 to add tap column)\n",
    "import ipywidgets as widgets #<- widget tool to generate button and tab for graphs\n",
    "from IPython.display import display #<- displays widgets\n",
    "from tkinter import Tk, filedialog #<- Tkinter is a GUI package\n",
    "print(\"done step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pick filepath (just run and click button from output)\n",
    "\n",
    "Run the following cell and click the button 'Select Folder' to pick a filepath.\n",
    "\n",
    "## Important: Later on, this script uses the total file path for each file to import and group data. That means if your folder has whatever your strain is named, the script will not work.\n",
    "\n",
    "(ex. if your folder has \"N2\" in it this script sees all files inside this folder as having the \"N2\" search key)\n",
    "\n",
    "## An easy fix is to just rename your folder to something else (make your strains lower-case, or just have the date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a179b0932ffe478a91871b8d52706635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Select Folder', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Joseph/Desktop/N2_parafilm_2022_08_20\n",
      "done step 2\n"
     ]
    }
   ],
   "source": [
    "### Select Folder App - After you run, you can select your folder for filepath\n",
    "button = widgets.Button(description = 'Select Folder') #<- Creates a button variable\n",
    "display(button) #<- displays this button on output\n",
    "def select_folder(b): #<- This is an action. Requires a variable, so I put in an arbitrary one 'b'\n",
    "    global folder_path #<- sets a variable as a global variable, not just within this action\n",
    "    Tk().withdraw() #<- Tkinter likes to create annoying empty windows. This removes them\n",
    "    folder_path = filedialog.askdirectory() #<- Opens up a file explorer window, and determines folder path\n",
    "    Tk().update()#<- below\n",
    "    Tk().destroy()#<- this and the line above it removes the file explorer window after a selection is made\n",
    "    print(folder_path) #<- this helps confirm that this action was performed\n",
    "    print('done step 2')\n",
    "button.on_click(select_folder) #<- describes what happens when you click on this button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. User Defined Variables (Add input here)\n",
    "\n",
    "Here, we add some constants to help you blaze through this code.\n",
    "\n",
    "3.1: Number of taps is pretty self-explanatory. How any taps does your experiment have? put in that number + 1 (N+1)!\n",
    "\n",
    "This may be a bit confusing, but this is due to some coding syntax that you don't have to worry about.\n",
    "\n",
    "3.2: Change your ISI number. This will be reflected in the name/title of the output figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (599, 601)), (2, (609, 611)), (3, (619, 621)), (4, (629, 631)), (5, (639, 641)), (6, (649, 651)), (7, (659, 661)), (8, (669, 671)), (9, (679, 681)), (10, (689, 691)), (11, (699, 701)), (12, (709, 711)), (13, (719, 721)), (14, (729, 731)), (15, (739, 741)), (16, (749, 751)), (17, (759, 761)), (18, (769, 771)), (19, (779, 781)), (20, (789, 791)), (21, (799, 801)), (22, (809, 811)), (23, (819, 821)), (24, (829, 831)), (25, (839, 841)), (26, (849, 851)), (27, (859, 861)), (28, (869, 871)), (29, (879, 881)), (30, (889, 891))]\n",
      "tap 1 tolerance=(599, 601)\n",
      "tap 2 tolerance=(609, 611)\n",
      "tap 3 tolerance=(619, 621)\n",
      "tap 4 tolerance=(629, 631)\n",
      "tap 5 tolerance=(639, 641)\n",
      "tap 6 tolerance=(649, 651)\n",
      "tap 7 tolerance=(659, 661)\n",
      "tap 8 tolerance=(669, 671)\n",
      "tap 9 tolerance=(679, 681)\n",
      "tap 10 tolerance=(689, 691)\n",
      "tap 11 tolerance=(699, 701)\n",
      "tap 12 tolerance=(709, 711)\n",
      "tap 13 tolerance=(719, 721)\n",
      "tap 14 tolerance=(729, 731)\n",
      "tap 15 tolerance=(739, 741)\n",
      "tap 16 tolerance=(749, 751)\n",
      "tap 17 tolerance=(759, 761)\n",
      "tap 18 tolerance=(769, 771)\n",
      "tap 19 tolerance=(779, 781)\n",
      "tap 20 tolerance=(789, 791)\n",
      "tap 21 tolerance=(799, 801)\n",
      "tap 22 tolerance=(809, 811)\n",
      "tap 23 tolerance=(819, 821)\n",
      "tap 24 tolerance=(829, 831)\n",
      "tap 25 tolerance=(839, 841)\n",
      "tap 26 tolerance=(849, 851)\n",
      "tap 27 tolerance=(859, 861)\n",
      "tap 28 tolerance=(869, 871)\n",
      "tap 29 tolerance=(879, 881)\n",
      "tap 30 tolerance=(889, 891)\n",
      "done step 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_taps = 30 ###<------ Taps in your experiment.\n",
    "\n",
    "number_taps = range(1, number_of_taps + 1)  #<- do not change this\n",
    "\n",
    "\n",
    "# if you have different ISIs in the same folder, then come back and change this \n",
    "# when you are graphing for the second set of data with the other ISI \n",
    "# (Generally data from same ISIs are graphed together)\n",
    "# If changing ISI mid-analysis, you can just skip straight to step 8 after running this cell again\n",
    "\n",
    "ISI = 10  ### <- What is your ISI? change accordingly\n",
    "first_tap = 600 ### <- when is your first tap? check your TRV files\n",
    "\n",
    "#Here, open up one of the trv files to determine the times for each of these taps. \n",
    "lower = np.arange(first_tap-1, first_tap-1+(number_of_taps*ISI), ISI) #(first tap, last tap+10s, ISI)\n",
    "upper = np.arange(first_tap+1, first_tap+1+(number_of_taps*ISI), ISI) #(first tap, last tap+10s, ISI)\n",
    "tolerances = list(zip(lower, upper)) \n",
    "taps = [i for i in range(1,number_of_taps+1)]\n",
    "\n",
    "#### Add 31st Tap Here --------------------------------------------------<------------\n",
    "# tolerances.append((1188,1191))\n",
    "# taps.append(31)\n",
    "\n",
    "\n",
    "#assign each tolerance to a tap number\n",
    "accurate_taps = list((zip(taps, tolerances)))\n",
    "print(accurate_taps)\n",
    "\n",
    "for pair in accurate_taps:\n",
    "   tap = pair[0]\n",
    "   tolerance = pair[1]\n",
    "   print(\"tap \"+str(tap), \"tolerance=\"+str(tolerance))\n",
    "\n",
    "print(\"done step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing Filelist From Source File/Select File (Just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_093722/N2_P_8_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_090154/N2_P_2_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_101520/N2_7_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_085200/N2_P_3_10x2_t96h20C_600s30x10s_C_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_093953/N2_P_1_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_092820/N2_P_9_10x2_t96h20C_600s30x10s_C_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_091210/N2_P_6_10x2_t96h20C_600s30x10s_C_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_095755/N2_4_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/Yes_Parafilm/20220820_092112/N2_P_5_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_094727/N2_NP_3_10x2_t96h20C_600s30x10s_C_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_095637/N2_NP_2_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_101243/N2_NP_5_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_105048/N2_NP_4_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_100319/N2_NP_6_10x2_t96h20C_600s30x10s_C_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_110745/N2_NP_7_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_103415/N2_NP_1_10x2_t96h20C_600s30x10s_A_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_102924/N2_NP_8_10x2_t96h20C_600s30x10s_B_2022_08_20.trv', '/Users/Joseph/Desktop/N2_parafilm_2022_08_20/No_Parafilm/20220820_101905/N2_NP_9_10x2_t96h20C_600s30x10s_C_2022_08_20.trv']\n",
      "done step 4\n"
     ]
    }
   ],
   "source": [
    "#folder_path = '/Users/Joseph/Desktop/AVR14_10sISI' #- manual folder path if Tkinter is acting up\n",
    "\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.trv'): #<- and takes out all files with a .trv (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "    \n",
    "print(filelist)\n",
    "print('done step 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Data Function (Just Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessData(strain): #<- an example of a user-defined function\n",
    "    strain_filelist = [x for x in filelist if strain in x] #<- goes through the list and filters for keyword\n",
    "    Strain_N = len(strain_filelist) #<- N per strain, or number of plates\n",
    "    Plate_N = 1\n",
    "    print(f'this strain/treatment has {Strain_N} plates') #<- will output as the first number\n",
    "    if Strain_N == 0:\n",
    "        raise AssertionError ('{} is not a good identifier'.format(strain))\n",
    "    else:\n",
    "        pass\n",
    "#     for f in strain_filelist:\n",
    "#         DF_Total = pd.concat(pd.read_csv(f, sep=' ', skiprows = 4, header = None))\n",
    "        DF_Total = pd.concat([pd.read_csv(f, sep=' ', skiprows = 4, header = None) for f in strain_filelist],\n",
    "                      ignore_index=True) #<- imports your data files\n",
    "#         DF_Total = DF_Total.dropna(axis = 1) #<- cleans your data\n",
    "        DF_Total = DF_Total.rename( #<- more cleaning\n",
    "                    {0:'time',\n",
    "                    2:'rev_before',\n",
    "                    3:'no_rev',\n",
    "                    4:'stim_rev',\n",
    "                    7:'dist',\n",
    "                    8:'dist_std',\n",
    "                    9:'dist_stderr',\n",
    "                    11:'dist_0th',\n",
    "                    12:'dist_1st',\n",
    "                    13:'dist_2nd',\n",
    "                    14:'dist_3rd',\n",
    "                    15:'dist_100th',\n",
    "                    18:'dura',\n",
    "                    19:'dura_std',\n",
    "                    20:'dura_stderr',\n",
    "                    22:'dura_0th',\n",
    "                    23:'dura_1st',\n",
    "                    24:'dura_2nd',\n",
    "                    25:'dura_3rd',\n",
    "                    26:'dura_100th'}, axis=1)\n",
    "        #check function here for NaN Columns\n",
    "        DF_Total['plate'] = 0\n",
    "        DF_Total['prob'] = DF_Total['stim_rev']/ (DF_Total['no_rev'] + DF_Total['stim_rev']) #<- calculate prob\n",
    "        DF_Total['speed'] = DF_Total['dist']/DF_Total['dura'] #<- calculate speed\n",
    "        DF_Total_rows = int(DF_Total.shape[0])\n",
    "        print(f'this strain/treatment has {DF_Total_rows} total taps') #<- Outputs as the second number. Check if you are missing taps!\n",
    "        DF_Final = DF_Total[[\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\"]].copy()\n",
    "\n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total,\n",
    "            'Final': DF_Final}\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "\n",
    "def assign_taps(DF, tolerances):\n",
    "    DF['taps'] = \"\"\n",
    "    for taps, tolerance in enumerate(tolerances): #[(99, 101), (109,111), ...]\n",
    "        tap_lower,tap_upper = tolerance\n",
    "        TimesInTapRange = DF['time'].between(tap_lower,tap_upper, inclusive=True)\n",
    "        DF.loc[TimesInTapRange,'taps'] = taps+1 #set the tap to i where times are between\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def insert_plates(df):   \n",
    "    \"\"\"This function inserts a plate column into a dataframe.\n",
    "    \n",
    "    :param df: any dataframe\n",
    "    :type: pandas.core.frame.DataFrame\n",
    "    \n",
    "    :return: dataframe with a plate column\n",
    "    :type: pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    df['plate']=(df['taps'] ==1).cumsum()\n",
    "\n",
    "\n",
    "            \n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Setting Experimental groups (Upgraded: Now Automated, Input Minimal/No Longer Required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strainnames=[]\n",
    "for f in filelist:\n",
    "    strainnames.append(f.split('/')[5]) \n",
    "    #adjust the number in [] above until you see your groups\n",
    "ustrainnames=list(set(strainnames))\n",
    "print(ustrainnames)\n",
    "\n",
    "nstrains=list(range(1,len(ustrainnames)+1))\n",
    "print(nstrains)\n",
    "\n",
    "StrainNames = {}\n",
    "StrainNames = {nstrains[i]: ustrainnames[i] for i in range(len(nstrains))}\n",
    "print(StrainNames)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just in case the above cell doesnt work, original cell and instruction still included below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the hardest part - From your naming convention, you need to pick a unique identifier for each group.\n",
    "\n",
    "This means that all of names of your files for that strain should have that in common but is not commone with across all other files! If you did a good job naming your files and following a good naming convention, this should be easy.\n",
    "\n",
    "## Be careful and really look hard in your naming structure. Note you want an unique identifier in the entire file path for the same group of files. An easy mistake is to have the strain name in the overall folder name, in this case if you use your strain name as a keyword it would include all files in that folder!\n",
    "\n",
    "For example, if all your N2 files have a certain pattern like \"N2_5x4\" in this following example:\n",
    "'/Users/Joseph/Desktop/AVR14_10sISI_TapHab_0710_2019/N2/20190710_141740/N2_5x4_f94h20c_100s30x10s10s_C0710ab.trv'\n",
    "\n",
    "Then you need to set that identifier for the strain keyword:\n",
    "'Strain_1' = 'N2_5x4'\n",
    "\n",
    "## Depending on how many strains you are running for comparison, you may need to add/delete some lines!\n",
    "\n",
    "## You are not naming your data groups here, we have a step for that later!\n",
    "## Here, you want to note down ALL the strains you have in the folder\n",
    "\n",
    "If you have just 2 strains, add hashtags (#) in front of the lines you do not need.\n",
    "If you need more strains, just add more lines, following the same format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell Is Now Defunct\n",
    "\n",
    "# #Format: 'Strain_#'' = 'unique_identifier'\n",
    "\n",
    "# ### Make into dictionary\n",
    "# StrainNames = {\n",
    "#     'Strain_1' : 'Yes_Parafilm',  #<- each strain will be designated to a unique identifier here\n",
    "#     'Strain_2' : 'No_Parafilm',\n",
    "# #     'Strain_3' : 'hipr-1_tm14191',\n",
    "# #     'Strain_4' : 'cpr-5_ok2344',\n",
    "# #     'Strain_5' : '2_P',\n",
    "# #     'Strain_6' : '3_P',\n",
    "# #     'Strain_7' : 'S1P11', #<- empty entries are for those hardcore trackers that tracks this many strains\n",
    "# #     'Strain_8' : 'S2P12',\n",
    "# #     'Strain_9' : 'S1P12',\n",
    "# #     'Strain_10' : 'S2P13',\n",
    "# #     'Strain_11' : 'S1P13',\n",
    "# #     'Strain_12' : 'S2P14',\n",
    "# #     'Strain_13' : 'S1P14',\n",
    "# #     'Strain_14' : 'S2P15',\n",
    "# #     'Strain_15' : '',\n",
    "# #     'Strain_10' : '',\n",
    "# #     'Strain_11' : '',\n",
    "# #     'Strain_12' : '',\n",
    "# #     'Strain_13' : '',\n",
    "# #     'Strain_14' : '',\n",
    "# #     'Strain_15' : '',\n",
    "# }\n",
    "# #...etc, etc\n",
    "\n",
    "# print('done step 6.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Process Data (just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLists = [0]  #<- generates empty list. 0 is there to account for python's index starting at 0. \n",
    "# we want indexing to start at 1 (when I say #1 I want the first point, not the second point)\n",
    "\n",
    "for s in StrainNames.values():#<- goes through the dictionary in step 6.1 and processes data\n",
    "    if not s == '':\n",
    "        DataLists.append(ProcessData(s)['Final']) #<- appends all data into a list of dataframes\n",
    "\n",
    "\n",
    "for df in DataLists[1:]: \n",
    "    assign_taps(df, tolerances)\n",
    "for df in DataLists[1:]:    \n",
    "    insert_plates(df)\n",
    "\n",
    "# print(x)\n",
    "# print(DataLists[0])\n",
    "# print(DataLists[1])\n",
    "#print(DataLists[2])\n",
    "#print(len(DataLists))        \n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(DataLists[3])\n",
    "# DataLists[3].loc[31:59,\"plate\"]=5\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(DataLists[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 (Now Automated, No Input Required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated=pd.concat(df.assign(Strain=StrainNames.get(i+1)) for i,df in enumerate(DataLists[1:]))\n",
    "print(TotalConcatenated)\n",
    "TotalConcatenated.to_csv(\"output.csv\")\n",
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case above cell doesn't work, below is original cell and instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7B*. Grouping Data and Naming (Optional: Add input here)\n",
    "\n",
    "Here, you get to name your data groups/strain! Name your groups however you like under between the quotation marks for each strain.\n",
    "\n",
    "For example: If your Strain1 is N2 and you wish for the group to be called N2,\n",
    "your line should look like:\n",
    "\n",
    "DataLists[x].assign(dataset = 'N2')\n",
    "\n",
    "## Go back to step 6.1 to check which strain is which item on the DataLists.\n",
    "In this example, the first item on DataLists is N2.\n",
    "\n",
    "\n",
    "## Remember: Put your name in quotes. (ex: 'N2' and not N2)\n",
    "\n",
    "As default, the names are set to the unique identifier labels.\n",
    "\n",
    "## Depending on the number of strains you are running the comparison, you may have to delete/add lines of code (following the same format). \n",
    "## Remember to add/delete commas too.\n",
    "\n",
    "# If you want to change your groups, you do that here. \n",
    "For example, if you have 5 strains in your folder but only want to compare between 2 or 3 strains, designate that here and follow through with steps 6 and 7. Once you are done, come back to step 6 and change your groups again (You are going to have to change your graph titles for the second run-through though)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This Cell Is Now Defunct \n",
    "\n",
    "# TotalConcatenated = pd.concat([ #<- this function joins your data together with an extra column for which group \n",
    "# #                         DataLists[1].assign(dataset = \"N2\"),\n",
    "# #                         DataLists[2].assign(dataset = \"glo-1 (tm3240)\"),\n",
    "# #                         DataLists[3].assign(dataset = \"bas-1 (tm351)\"),\n",
    "# #                         DataLists[4].assign(dataset = \"vps-35 (ok1880)\"),\n",
    "#                         DataLists[1].assign(dataset = StrainNames.get(\"Strain_1\")),\n",
    "#                         DataLists[2].assign(dataset = StrainNames.get(\"Strain_2\")),\n",
    "# #                         DataLists[3].assign(dataset = StrainNames.get(\"Strain_3\")),\n",
    "# #                         DataLists[4].assign(dataset = StrainNames.get(\"Strain_4\")),\n",
    "# #                         DataLists[6].assign(dataset = StrainNames.get(\"Strain_6\")),\n",
    "# #                         DataLists[7].assign(dataset = StrainNames.get(\"Strain_7\")),\n",
    "# #                         DataLists[8].assign(dataset = StrainNames.get(\"Strain_8\")),\n",
    "# #                         DataLists[9].assign(dataset = StrainNames.get(\"Strain_9\")),\n",
    "# #                         DataLists[10].assign(dataset = StrainNames.get(\"Strain_10\")),\n",
    "# #                         DataLists[11].assign(dataset = StrainNames.get(\"Strain_11\")),\n",
    "# #                         DataLists[12].assign(dataset = StrainNames.get(\"Strain_12\")),\n",
    "# #                         DataLists[13].assign(dataset = StrainNames.get(\"Strain_13\")),\n",
    "# #                         DataLists[14].assign(dataset = StrainNames.get(\"Strain_14\")),\n",
    "# #                           DataLists[2].assign(dataset = \"glo-1 (zu391)\"),\n",
    "# #                           DataLists[3].assign(dataset = \"src-1 (ok2685)\"),\n",
    "# #                           DataLists[4].assign(dataset = \"dpy-22 (e652)\"),\n",
    "# #                           DataLists[4].assign(dataset = \"dpy-22 (sy622)\"),\n",
    "#                           #DataLists[6].assign(dataset = \"Pan-neuronal Specific\"),\n",
    "#                           #DataLists[7].assign(dataset = \"GOA1 Mutant (n1134)\"),\n",
    "#                           #DataLists[8].assign(dataset = \"GOA1 Mutant (n3055)\"),\n",
    "# #                           DataLists[5].assign(dataset = StrainNames.get(\"Strain_5\")),\n",
    "# #                         DataLists[5].assign(dataset = \"StrainNameOnePoster\"), #<----- example of custom name\n",
    "                          \n",
    "# ])\n",
    "# # ...etc etc\n",
    "\n",
    "# TotalConcatenated.reset_index(inplace=False)\n",
    "# print(TotalConcatenated)\n",
    "\n",
    "# #if TotalConcatenated[\"taps\"].loc[ind] is not 1:\n",
    "# #   TotalConcatenated[\"taps\"].loc[ind:indices[c+1]] = list(range(1,len(TotalConcatenated[\"taps\"].loc[ind:indices[c+1]])+1))\n",
    "# # missing_taps(TotalConcatenated, accurate_taps, tolerances)\n",
    "\n",
    "# print('done step 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpy22=TotalConcatenated[TotalConcatenated['dataset']=='dpy-22_e652']\n",
    "# print(dpy22)\n",
    "# dpy22.to_csv('dpy22.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Colour Palette - Only run the below cell ONCE\n",
    "\n",
    "The following code sets the colour palette for the whole experiment - and then designate one colour to each strain. After this, if as you are graphing you take away some strains, you can do so with the colours still matching accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want the default colour palette #\n",
    "strains = TotalConcatenated['dataset'].unique()\n",
    "pal = dict(zip(strains, sns.color_palette(\"deep\", n_colors=len(strains))))\n",
    "pal = dict(zip(strains, ['darkgray','gainsboro']))\n",
    "print('palette is:' + str(pal))\n",
    "\n",
    "# IF YOU WANT TO CUSTOMIZE THE COLOR PALETTE OF THE GRAPHS\n",
    "# pal = dict(zip(strains, ['color1','color2', ...etc etc]))\n",
    "\n",
    "print('done setting colour palette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs final data onto a spreadsheet\n",
    "TotalConcatenated.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5: BONUS - Graph by plates to check for anomolies across each strain/treatment\n",
    "\n",
    "Here, we will be graphing each strain on their own by their individual plates - this will help us find any anomolies or outliers that we can then exclude!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Strain_pal = sns.choose_colorbrewer_palette('sequential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StrainConcatenated = TotalConcatenated[\n",
    "    TotalConcatenated.dataset == \"hipr-1_tm14191\"] #Change/dictate which strain you are analyzing\n",
    "StrainName = \"hipr-1_tm14191\" #Also change this, for labeling purposes\n",
    "\n",
    "\n",
    "out1 = widgets.Output() #<- this is part of the code that helps display your graphs in tabs\n",
    "out2 = widgets.Output()\n",
    "out3 = widgets.Output()\n",
    "# out4 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2, out3]) #<- more code to support tab display\n",
    "tab.set_title(0, 'Probability')\n",
    "# tab.set_title(1, 'Distance')\n",
    "tab.set_title(1, 'Duration')\n",
    "tab.set_title(2, 'Speed')\n",
    "display(tab)\n",
    "\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "\n",
    "# Probability\n",
    "with out1:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.pointplot(x=\"taps\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"prob\",  \n",
    "                 data = StrainConcatenated,\n",
    "                 hue = 'plate', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = Strain_pal, #<- Change colour palette here if you like\n",
    "                 ci = 95) #<- Confidence interval. 95 = standard error\n",
    "    plt.xlabel(\"Taps\") #<- X-axis title\n",
    "    plt.ylabel(\"Probability\") #<- Y-Axis title\n",
    "    plt.title(f\"{StrainName} Probability of Tap Habituation, {ISI}ISI\") #<- Figure Title\n",
    "    plt.ylim(0,1)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    # plt.savefig(f'{StrainName}_Probability_{ISI}ISI_ByPlate.png', format='png', dpi=450) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# # Distance\n",
    "# with out2:\n",
    "#     plt.figure(linewidth = 2.5)\n",
    "#     plt.figure(figsize=(12,10))\n",
    "#     plt.gca().xaxis.grid(False)\n",
    "#     ax = sns.pointplot(x=\"taps\", \n",
    "#                  y=\"dist\", \n",
    "#                  data = StrainConcatenated,\n",
    "#                  hue = 'plate',\n",
    "#                  palette = Strain_pal,\n",
    "#                  ci = 95)\n",
    "#     plt.xlabel(\"Taps\", fontsize = '12')\n",
    "#     plt.ylabel(\"Distance\", fontsize = '12')\n",
    "#     plt.title(f\"{StrainName} Distance of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "#     plt.ylim(0,1.5)\n",
    "#     ax.legend(loc = 'upper right', fontsize = '12')\n",
    "#     plt.savefig(f'{StrainName}_Distance_{ISI}ISI_ByPlate.png', format='png', dpi=450)\n",
    "#     plt.show()\n",
    "\n",
    "# Duration\n",
    "with out2:\n",
    "    plt.figure(linewidth = 2.5)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    ax = sns.pointplot(x=\"taps\", \n",
    "                 y=\"dura\", \n",
    "                 data = StrainConcatenated,\n",
    "                 hue = 'plate',\n",
    "                 palette = Strain_pal,\n",
    "                 ci = 95)\n",
    "    plt.xlabel(\"Taps\", fontsize = '12')\n",
    "    plt.ylabel(\"Duration\", fontsize = '12')\n",
    "    plt.title(f\"{StrainName} Duration of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "    plt.ylim(0,3)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12')\n",
    "    # plt.savefig(f'{StrainName}_Duration_{ISI}ISI_ByPlate.png', format='png', dpi=450)\n",
    "    plt.show()\n",
    "\n",
    "# Speed\n",
    "with out3:\n",
    "    plt.figure(linewidth = 2.5)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    ax = sns.pointplot(x=\"taps\", \n",
    "                 y=\"speed\", \n",
    "                 data = StrainConcatenated,\n",
    "                 hue = 'plate',\n",
    "                 palette = Strain_pal,\n",
    "                 ci = 95)\n",
    "    plt.xlabel(\"Taps\", fontsize = '12')\n",
    "    plt.ylabel(\"Speed\", fontsize = '12')\n",
    "    plt.title(f\"{StrainName} Speed of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "    plt.ylim(0,0.5)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12')\n",
    "    # plt.savefig(f'{StrainName}_Speed_{ISI}ISI.png_ByPlate', format='png', dpi=450)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated_S1s=TotalConcatenated[TotalConcatenated[\"dataset\"==[]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Graph Data (Probability, Distance, Duration, Speed of Tap Habituation)\n",
    "\n",
    "## Here, feel free to change the graph title and axis labels! Images are automatically saved in your folder with your data!\n",
    "\n",
    "Note: It has been agreed by the lab that distance is quite an outdated measure, and the three top measures we consider are:\n",
    "\n",
    "## probability, duration and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix=\"S1vsS2_\"\n",
    "\n",
    "out1 = widgets.Output() #<- this is part of the code that helps display your graphs in tabs\n",
    "out2 = widgets.Output()\n",
    "out3 = widgets.Output()\n",
    "out4 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2, out3, out4]) #<- more code to support tab display\n",
    "tab.set_title(0, 'Probability')\n",
    "tab.set_title(1, 'Distance')\n",
    "tab.set_title(2, 'Duration')\n",
    "tab.set_title(3, 'Speed')\n",
    "display(tab)\n",
    "\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "sns.set_context(\"notebook\")\n",
    "# Probability\n",
    "with out1:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.pointplot(x=\"taps\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"prob\",  \n",
    "                 data = TotalConcatenated,\n",
    "                 hue = 'dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = pal, #<- Change colour palette here if you like\n",
    "                 ci = 68) #<- Confidence interval. 95 = standard error\n",
    "    plt.xlabel(\"Taps\") #<- X-axis title\n",
    "    plt.ylabel(\"Probability\") #<- Y-Axis title\n",
    "    plt.title(f\"Probability of Tap Habituation, {ISI}ISI\") #<- Figure Title\n",
    "    plt.ylim(0,1)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    plt.savefig(f'Probability_{ISI}ISI.png', format='png', dpi=450) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# Distance\n",
    "with out2:\n",
    "    plt.figure(linewidth = 2.5)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    ax = sns.pointplot(x=\"taps\", \n",
    "                 y=\"dist\", \n",
    "                 data = TotalConcatenated,\n",
    "                 hue = 'dataset',\n",
    "                 palette = pal,\n",
    "                 ci = 68  #ci=68 for sem\n",
    "                      )\n",
    "    plt.xlabel(\"Taps\", fontsize = '12')\n",
    "    plt.ylabel(\"Distance\", fontsize = '12')\n",
    "    plt.title(f\"Distance of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "    plt.ylim(0,None)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12')\n",
    "    plt.savefig(f'Distance_{ISI}ISI.png', format='png', dpi=450)\n",
    "    plt.show()\n",
    "\n",
    "# Duration\n",
    "with out3:\n",
    "    plt.figure(linewidth = 2.5)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    ax = sns.pointplot(x=\"taps\", \n",
    "                 y=\"dura\", \n",
    "                 data = TotalConcatenated,\n",
    "                 hue = 'dataset',\n",
    "                 palette = pal,\n",
    "                 ci = 68  #ci=68 for sem\n",
    "                      )\n",
    "    plt.xlabel(\"Taps\", fontsize = '12')\n",
    "    plt.ylabel(\"Duration\", fontsize = '12')\n",
    "    plt.title(f\"Duration of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "    plt.ylim(0,None)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12')\n",
    "    plt.savefig(f'Duration_{ISI}ISI.png', format='png', dpi=450)\n",
    "    plt.show()\n",
    "\n",
    "# Speed\n",
    "with out4:\n",
    "    plt.figure(linewidth = 2.5)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    ax = sns.pointplot(x=\"taps\", \n",
    "                 y=\"speed\", \n",
    "                 data = TotalConcatenated,\n",
    "                 hue = 'dataset',\n",
    "                 palette = pal,\n",
    "                 ci = 68 #ci=68 for sem\n",
    "                      )\n",
    "    plt.xlabel(\"Taps\", fontsize = '12')\n",
    "    plt.ylabel(\"Speed\", fontsize = '12')\n",
    "    plt.title(f\"Speed of Tap Habituation, {ISI}ISI\", fontsize = '16')\n",
    "    plt.ylim(0,None)\n",
    "    ax.legend(loc = 'upper right', fontsize = '12')\n",
    "    plt.savefig(f'Speed_{ISI}ISI.png', format='png', dpi=450)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA and By-Tap Box-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalConcatenated[['Day', 'Parafilm']] = TotalConcatenated['dataset'].str.split('_', 1, expand=True)\n",
    "# TotalConcatenated[['S', 'Seed']] = TotalConcatenated['Seeed'].str.split('S', 1, expand=True)\n",
    "print(TotalConcatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_anova = pg.anova(dv='prob', between=['Day', 'Parafilm'], data=TotalConcatenated,\n",
    "               detailed=True).round(5)\n",
    "dist_anova = pg.anova(dv='dist', between=['Day', 'Parafilm'], data=TotalConcatenated,\n",
    "               detailed=True).round(5)\n",
    "duration_anova = pg.anova(dv='dura', between=['Day', 'Parafilm'], data=TotalConcatenated,\n",
    "               detailed=True).round(5)\n",
    "speed_anova = pg.anova(dv='speed', between=['Day', 'Parafilm'], data=TotalConcatenated,\n",
    "               detailed=True).round(5)\n",
    "print(\"Probability ANOVA\")\n",
    "print(prob_anova)\n",
    "print(\"Distance ANOVA\")\n",
    "print(dist_anova)\n",
    "print(\"Duration ANOVA\")\n",
    "print(duration_anova)\n",
    "print(\"Speed ANOVA\")\n",
    "print(speed_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TapToAnalyze=1\n",
    "\n",
    "FirstTap = TotalConcatenated[TotalConcatenated[\"taps\"]==TapToAnalyze]\n",
    "print(FirstTap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_anova = pg.anova(dv='prob', between=['Day', 'Parafilm'], data=FirstTap,\n",
    "               detailed=True).round(3)\n",
    "dist_anova = pg.anova(dv='dist', between=['Day', 'Parafilm'], data=FirstTap,\n",
    "               detailed=True).round(3)\n",
    "duration_anova = pg.anova(dv='dura', between=['Day', 'Parafilm'], data=FirstTap,\n",
    "               detailed=True).round(3)\n",
    "speed_anova = pg.anova(dv='speed', between=['Day', 'Parafilm'], data=FirstTap,\n",
    "               detailed=True).round(3)\n",
    "print(f\"Tap_{TapToAnalyze}_Probability ANOVA\")\n",
    "print(prob_anova)\n",
    "print(f\"Tap_{TapToAnalyze}_Distance ANOVA\")\n",
    "print(dist_anova)\n",
    "print(f\"Tap_{TapToAnalyze}_Duration ANOVA\")\n",
    "print(duration_anova)\n",
    "print(f\"Tap_{TapToAnalyze}_Speed ANOVA\")\n",
    "print(speed_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pairwise = pg.pairwise_tests(dv='prob', between=['Day', 'Parafilm'], data=FirstTap).round(3)\n",
    "dist_pairwise = pg.pairwise_tests(dv='dist', between=['Day', 'Parafilm'], data=FirstTap).round(3)\n",
    "dura_pairwise = pg.pairwise_tests(dv='dura', between=['Day', 'Parafilm'], data=FirstTap).round(3)\n",
    "speed_pairwise = pg.pairwise_tests(dv='speed', between=['Day', 'Parafilm'], data=FirstTap).round(3)\n",
    "print(f\"Tap_{TapToAnalyze}_Probability Pairwise\")\n",
    "print(prob_pairwise)\n",
    "print(f\"Tap_{TapToAnalyze}_Distance Pairwise\")\n",
    "print(dist_pairwise)\n",
    "print(f\"Tap_{TapToAnalyze}_Duration Pairwise\")\n",
    "print(dura_pairwise)\n",
    "print(f\"Tap_{TapToAnalyze}_Speed Pairwise\")\n",
    "print(speed_pairwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pairwise_tukey=FirstTap.pairwise_tukey(dv='dist', between='Plate').round(3)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(prob_pairwise_tukey)\n",
    "    print(prob_pairwise_tukey[prob_pairwise_tukey['p-tukey']<= 0.05])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted=pd.melt(TotalConcatenated, id_vars=[\"time\",\"plate\",\"taps\",\"dataset\"], value_vars=[\"dura\", \"prob\", \"dist\", \"speed\"], var_name=\"Metric\", value_name=\"Measure\")\n",
    "print(melted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g = sns.FacetGrid(melted, col=\"Metric\",  row=\"taps\", sharey='col', col_order=['prob','dura','dist','speed'])\n",
    "g.map_dataframe(sns.boxplot, x=\"dataset\", y=\"Measure\")\n",
    "g.set_xticklabels(rotation=90)\n",
    "# g.axes[0].set_ylim((0,1))\n",
    "# g.axes[1].set_ylim((0,3.5))\n",
    "# g.axes[2].set_ylim((0,1))\n",
    "# g.axes[3].set_ylim((0,0.4))\n",
    "\n",
    "g.savefig('map_plot.pdf', format='pdf', dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 3 taps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taps1to3=melted[melted.taps<=3]\n",
    "# Can customize above line to get data for exact tap numbers you need\n",
    "\n",
    "g = sns.FacetGrid(taps1to3, col=\"Metric\",  row=\"taps\", sharey='col', col_order=['prob','dura','dist','speed'])\n",
    "g.map_dataframe(sns.boxplot, x=\"dataset\", y=\"Measure\")\n",
    "g.set_xticklabels(rotation=90)\n",
    "# g.axes[0].set_ylim((0,1))\n",
    "# g.axes[1].set_ylim((0,3.5))\n",
    "# g.axes[2].set_ylim((0,1))\n",
    "# g.axes[3].set_ylim((0,0.4))\n",
    "\n",
    "g.savefig('smaller_map_plot.png', format='png', dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done Tap-Habituation portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worm Size Measurement Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing .DAT Filelist for Worm Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_path = '/Users/Joseph/Desktop/lrk1_ATR_NoATR_08_15_2019'\n",
    "print(folder_path)\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.dat'): #<- and takes out all files with a .dat (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "    \n",
    "print(filelist)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process .dat Data Function (Just Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat_ProcessData(strain): #<- an example of a user-defined function\n",
    "    strain_filelist = [x for x in filelist if strain in x] #<- goes through the list and filters for keyword\n",
    "    Strain_N = len(strain_filelist) #<- N per strain, or number of plates\n",
    "    Plate_N = 1\n",
    "    print(f'this strain/treatment has {Strain_N} plates') #<- will output as the first number\n",
    "    if Strain_N == 0:\n",
    "        raise AssertionError ('{} is not a good identifier'.format(strain))\n",
    "    else:\n",
    "        pass\n",
    "#     for f in strain_filelist:\n",
    "#         DF_Total = pd.concat(pd.read_csv(f, sep=' ', skiprows = 4, header = None))\n",
    "        DF_Total = pd.concat([pd.read_csv(f, sep=' ', header = None) for f in strain_filelist],\n",
    "                      ignore_index=True) #<- imports your data files\n",
    "#         DF_Total = DF_Total.dropna(axis = 1) #<- cleans your data\n",
    "        DF_Total = DF_Total.rename( #<- more cleaning\n",
    "                    {0:'Time',\n",
    "                    1:'n',\n",
    "                    2:'Number',\n",
    "                    3:'Instantaneous Speed',\n",
    "                    4:'Interval Speed',\n",
    "                    5:'Bias',\n",
    "                    6:'Tap',\n",
    "                    7:'Puff',\n",
    "                    8:'x',\n",
    "                    9:'y',\n",
    "                    10:'Width',\n",
    "                    11:'Length',\n",
    "                    12:'Area',\n",
    "                    13:'Angular Speed',\n",
    "                    14:'Aspect Ratio',\n",
    "                    15:'Kink',\n",
    "                    16:'Curve',\n",
    "                    17:'Crab'}, axis=1)\n",
    "        #check function here for NaN Columns\n",
    "        DF_Total['plate'] = 0\n",
    "        # DF_Total['prob'] = DF_Total['stim_rev']/ (DF_Total['no_rev'] + DF_Total['stim_rev']) #<- calculate prob\n",
    "        # DF_Total['speed'] = DF_Total['dist']/DF_Total['dura'] #<- calculate speed\n",
    "        # DF_Total_rows = int(DF_Total.shape[0])\n",
    "        # print(f'this strain/treatment has {DF_Total_rows} total taps') #<- Outputs as the second number. Check if you are missing taps!\n",
    "        # DF_Final = DF_Total[[\"time\", \"dura\", \"dist\", \"prob\", \"speed\", \"plate\"]].copy()\n",
    "\n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total\n",
    "            # 'Final': DF_Final\n",
    "    }\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set StrainNames Dictionary (Automated - no input required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strainnames2=[]\n",
    "for f in filelist:\n",
    "    strainnames2.append(f.split('/')[5]) \n",
    "    #adjust the number in [] above until you see your groups\n",
    "ustrainnames2=list(set(strainnames2))\n",
    "print(ustrainnames2)\n",
    "\n",
    "nstrains2=list(range(1,len(ustrainnames2)+1))\n",
    "print(nstrains2)\n",
    "\n",
    "StrainNames2 = {}\n",
    "StrainNames2 = {nstrains2[i]: ustrainnames2[i] for i in range(len(nstrains2))}\n",
    "print(StrainNames2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case the above cell doesn't work as intended, the original code (commented out) is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Format: Strain_# = 'unique_identifier'\n",
    "\n",
    "# ### Make into dictionary\n",
    "# StrainNames = {\n",
    "#     'Strain_1' : 'No_Parafilm',   #<- each strain will be designated to a unique identifier here\n",
    "#     'Strain_2' : 'Yes_Parafilm',\n",
    "# #     'Strain_3' : 'e1112_OffFood',\n",
    "# #     'Strain_4' : 'e1112_OnFood',\n",
    "# #     'Strain_5' : 'Test_OffFood',\n",
    "# #     'Strain_6' : 'Test_OnFood',\n",
    "# #     'Strain_5' : 'N2_NoFood',\n",
    "# #     'Strain_6' : 'N2_Food',\n",
    "# #     'Strain_9' : 'LX636_NoFood',  #<- empty entries are for those hardcore trackers that tracking this many strains\n",
    "# #     'Strain_10' : 'LX636_Food',\n",
    "# #     'Strain_11' : '',\n",
    "# #     'Strain_12' : '',\n",
    "# #     'Strain_13' : '',\n",
    "# #     'Strain_14' : '',\n",
    "# #     'Strain_15' : '',\n",
    "# }\n",
    "# #...etc, etc\n",
    "\n",
    "# print('done step 6.1')\n",
    "# print(StrainNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_DataLists = [0] #<- generates empty list. 0 is there to account for python's index starting at 0. \n",
    "# we want indexing to start at 1 (when I say #1 I want the first point, not the second point)\n",
    "\n",
    "for s in tqdm(StrainNames2.values()): #<- goes through the dictionary in step 6.1 and processes data\n",
    "    if not s == '':\n",
    "        dat_DataLists.append(dat_ProcessData(s)['Confirm']) #<- appends all data into a list of dataframes\n",
    "\n",
    "# print(DataLists[2])\n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data And Naming (Automated - No Input Required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline=pd.concat(df.assign(Strain=StrainNames2.get(i+1)) for i,df in enumerate(dat_DataLists[1:]))\n",
    "print(baseline)\n",
    "baseline.to_csv(\"baseline_output.csv\")\n",
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If upgraded cell doesn't work, below is original code (commented out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # <------------------- This cell is now DEFUNCT -----------------------\n",
    "\n",
    "\n",
    "# #to add a line, add a comma to the last line and press 'enter' to type into a new line\n",
    "\n",
    "\n",
    "# baseline = pd.concat([DataLists[1].assign(Strain = \"No Parafilm\"),\n",
    "#                                DataLists[2].assign(Strain = \"Parafilm\"),\n",
    "#                               ])\n",
    "# # baseline=baseline.dropna()\n",
    "# baseline = baseline.reset_index(drop=True)\n",
    "# print(baseline)\n",
    "# baseline.to_csv(\"baseline_output.csv\")\n",
    "# print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformating Dataframe, taking baseline measures from 100s - 500s (before tap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_NP=baseline[baseline.Strain=='No_Parafilm']\n",
    "baseline_NP.Strain='No Parafilm'\n",
    "baseline_P=baseline[baseline.Strain=='Yes_Parafilm']\n",
    "baseline_P.Strain='Parafilm'\n",
    "baseline_NP['plate']=((baseline_NP.Time <=0.05)&(baseline_NP.Time >=0)).cumsum()\n",
    "baseline_P['plate']=((baseline_P.Time <=0.05)&(baseline_P.Time >=0)).cumsum()\n",
    "# print(baseline_NP)\n",
    "# print(baseline_P)\n",
    "data=pd.concat([baseline_NP,baseline_P])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data=data[['Strain','plate','Time','Number','Width','Length','Area']]\n",
    "some_data=some_data.rename(columns={'Strain': 'Dataset', 'plate':'Plate'})\n",
    "some_data=some_data[(some_data.Time <= 500) & (some_data.Time >= 100)]\n",
    "\n",
    "print(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the mean measures of each plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data_means= some_data.groupby([\"Dataset\", 'Plate'], as_index=False).mean()\n",
    "print(some_data_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = widgets.Output() #<- this is part of the code that helps display your graphs in tabs\n",
    "out2 = widgets.Output()\n",
    "out3 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2, out3]) #<- more code to support tab display\n",
    "tab.set_title(0, 'Width')\n",
    "tab.set_title(1, 'Length')\n",
    "tab.set_title(2, 'Area')\n",
    "display(tab)\n",
    "\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "sns.set_context(\"talk\")\n",
    "# Width\n",
    "with out1:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.barplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Width\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 ci = 68,\n",
    "                 dodge=False) #<- Confidence interval. 68 = standard error\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Width (mm)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Width\") #<- Figure Title\n",
    "    ax.legend_.remove()\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    # plt.savefig(f'Probability_{ISI}ISI.png', format='png', dpi=900) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# Length\n",
    "with out2:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.barplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Length\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 ci = 68,\n",
    "                 dodge=False) #<- Confidence interval. 68 = standard error\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Length (mm)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Length\") #<- Figure Title\n",
    "    ax.legend_.remove()\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    # plt.savefig(f'Probability_{ISI}ISI.png', format='png', dpi=900) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# Area\n",
    "with out3:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.barplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Area\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 ci = 68,\n",
    "                dodge=False) #<- Confidence interval. 68 = standard error\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Area (mm^2)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Area\") #<- Figure Title\n",
    "    ax.legend_.remove()\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    # plt.savefig(f'Probability_{ISI}ISI.png', format='png', dpi=900) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = widgets.Output() #<- this is part of the code that helps display your graphs in tabs\n",
    "out2 = widgets.Output()\n",
    "out3 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2, out3]) #<- more code to support tab display\n",
    "tab.set_title(0, 'Width')\n",
    "tab.set_title(1, 'Length')\n",
    "tab.set_title(2, 'Area')\n",
    "display(tab)\n",
    "\n",
    "PROPS = {\n",
    "    'boxprops':{'edgecolor':'k'},\n",
    "    'medianprops':{'color':'k'},\n",
    "    'whiskerprops':{'color':'k'},\n",
    "    'capprops':{'color':'k'}\n",
    "}\n",
    "\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "sns.set_context(\"talk\")\n",
    "# Width\n",
    "with out1:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.boxplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Width\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 showfliers=False,\n",
    "                 dodge=False,\n",
    "                 **PROPS) #<- Confidence interval. 68 = standard error\n",
    "    ax.legend_.remove()\n",
    "    ax=sns.stripplot(x=\"Dataset\",\n",
    "                     y=\"Width\",\n",
    "                     data=some_data_means,\n",
    "                     size=6,\n",
    "                     color=\"k\")\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Width (mm)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Width\") #<- Figure Title\n",
    "    # plt.setp(ax.artists, edgecolor = 'k')\n",
    "    # plt.setp(ax.lines, color='k')\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    plt.savefig(\"Average Worm Width.png\", format='png', dpi=450) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# Length\n",
    "with out2:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.boxplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Length\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 showfliers=False,\n",
    "                 dodge=False,\n",
    "                **PROPS) #<- Confidence interval. 68 = standard error\n",
    "    ax.legend_.remove()\n",
    "    ax=sns.stripplot(x=\"Dataset\",\n",
    "                 y=\"Length\",\n",
    "                 data=some_data_means,\n",
    "                 size=6,\n",
    "                 color=\"k\")\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Length (mm)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Length\") #<- Figure Title\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    plt.savefig(\"Average Worm Length.png\", format='png', dpi=450) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()\n",
    "\n",
    "# Area\n",
    "with out3:\n",
    "    plt.figure(linewidth = 2.5) #<- Make your figure lines THICCCC for clean display (posters)\n",
    "    # plt.figure(figsize=(12,10)) #<- set your figure size (width, length)\n",
    "    plt.gca().xaxis.grid(False) #<- gets rid of x-axis markers to make data look clean \n",
    "    ax = sns.boxplot(x=\"Dataset\", #<- Here we use seaborn as our graphing package. \n",
    "                 y=\"Area\",  \n",
    "                 data = some_data_means,\n",
    "                 hue = 'Dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "                 palette = ['darkgray','gainsboro'], #<- Change colour palette here if you like\n",
    "                 showfliers=False,\n",
    "                dodge=False,\n",
    "                **PROPS) #<- Confidence interval. 68 = standard error\n",
    "    ax.legend_.remove()\n",
    "    ax=sns.stripplot(x=\"Dataset\",\n",
    "                 y=\"Area\",\n",
    "                 data=some_data_means,\n",
    "                 size=6,\n",
    "                 color=\"k\")\n",
    "    plt.xlabel(\"\") #<- X-axis title\n",
    "    plt.ylabel(\"Worm Area (mm^2)\") #<- Y-Axis title\n",
    "    plt.title(\"Average Worm Area\") #<- Figure Title\n",
    "    # plt.ylim(0,1)\n",
    "    # ax.legend(loc = 'upper right', fontsize = '12') #<- location of your legend\n",
    "    plt.savefig(\"Average Worm Area.png\", format='png', dpi=450) #<- saves your file to your folder at certain DPI\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Consideration (Weighted V.S. Unweighted Plate Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_means= some_data.groupby([\"Dataset\"], as_index=False).mean()\n",
    "print(unweighted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_data=some_data_means.groupby(\n",
    "    some_data_means.Dataset).apply(\n",
    "    lambda x: np.average(\n",
    "        x.Width, weights=x.Number))\n",
    "print(weighted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_se(input_df):\n",
    "    weights = input_df['Number']\n",
    "    vals = input_df['Area']\n",
    "\n",
    "    weighted_avg = np.average(vals, weights=weights)\n",
    "    \n",
    "    numer = np.sum(weights * (vals - weighted_avg)**2)\n",
    "    denom = ((vals.count()-1)/vals.count())*np.sum(weights)\n",
    "    \n",
    "    return np.sqrt(numer/denom)/np.sqrt(np.sum(weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
