{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook UI to graph your speed trace (with opto) data!\n",
    "\n",
    "Version 1.3 - Joseph Liang, Rankin Lab\n",
    "Updated:\n",
    "1. Upgraded folder path selection application\n",
    "2. Upgraded dataset management (less moving parts for end-user)\n",
    "3. output changed from tif -> png\n",
    "\n",
    "## Known bug: Step 2 an empty windows displays in Mac. May also apply to linux/windows.\n",
    "\n",
    "## Beginner Essentials:\n",
    "1. Shift-Enter to run each cell. After you run, you should see an output \"done step #\". If not, an error has occured\n",
    "2. When inputting your own code/revising the code, make sure you close all your quotation marks '' and brackets (), [], {}.\n",
    "3. Don't leave any commas (,) hanging! (make sure an object always follows a comma. If there is nothing after a comma, remove the comma!\n",
    "4. Learning to code? Each line of code is annotated to help you understand how this code works!\n",
    "\n",
    "## 3. Run all cells/steps sequentially, even the ones that do not require input\n",
    "\n",
    "## Steps that require input: #3, #6.1, #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Packages Required (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #<- package used to import and organize data\n",
    "import numpy as np #<- package used to import and organize data\n",
    "import seaborn as sns #<- package used to plot graphs\n",
    "from matplotlib import pyplot as plt #<- package used to plot graphs\n",
    "import os #<- package used to work with system filepaths\n",
    "from ipywidgets import widgets #<- widget tool to generate button\n",
    "from IPython.display import display #<- displays button\n",
    "from tkinter import Tk, filedialog #<- Tkinter is a GUI package\n",
    "print(\"done step 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pick filepath (just run and click button)\n",
    "\n",
    "Run the following cell and clicke the button 'Select Folder' to pick a filepath.\n",
    "\n",
    "## Important: Later on, this script uses the total file path for each file to import and group data. That means if your folder has whatever your strain is named, the script will not work.\n",
    "\n",
    "(ex. if your folder has \"N2\" in it this script sees all files inside this folder as having the \"N2\" search key)\n",
    "\n",
    "## An easy fix is to just rename your folder to something else (make your strains lower-case, or just have the date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select Folder App - After you run, you can select your folder for filepath\n",
    "button = widgets.Button(description = 'Select Folder') #<- creates a button variable\n",
    "display(button) #<- displays the button in output\n",
    "\n",
    "def select_folder(b): #<- defines an action. This action requires a variable, so an arbitrary one 'b' is there\n",
    "    global folder_path #<- sets a variable as a global variable, not just within this action\n",
    "    #Tk().withdraw() #<- Tkinter likes to create annoying empty windows. This removes them\n",
    "    folder_path = filedialog.askdirectory() #<- Opens up a file explorer window, and determines folder path\n",
    "    #Tk().update() #<- below\n",
    "    #Tk().destroy() #<- this and the line above it removes the file explorer window after a selection is made\n",
    "    print(folder_path) #<- this helps confirm that this action was performed\n",
    "    print('done step 2')\n",
    "button.on_click(select_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. User Defined Variables (Add input here)\n",
    "\n",
    "Here, we add some constants to help you blaze through this code.\n",
    "\n",
    "## 3.1: Setting time bins\n",
    "pretty self explanatory\n",
    "\n",
    "## 3.2: Setting light flashes (for visualization of light pulses in opto experiments)\n",
    "Here you are generating a separate dataframe to draw out light bars on your graph to visualize your light pulses. This will take a bit of elementary-level math. Think of it as drawing (connecting-the-dots style) rectangles that are 0.5 high strung-together. Start at (0,0), then (x1,0), then (x1, y1) ... etc\n",
    "\n",
    "____|-----|______|-----|____ etc.  \n",
    "\n",
    "Once you have that written down, put all the y's together in one dataframe, and the x's together in the other one..\n",
    "\n",
    "## 3.3: Setting view range for your graph\n",
    "Top, bottom = y axis view range\n",
    "left, right = x axis view range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 = {300: 310, 370: 380, 440: 450, 510: 520, 580: 590, 650: 660, 720: 730, 790: 800, 860: 870, 930: 940}\n",
      "[(300, 310), (370, 380), (440, 450), (510, 520), (580, 590), (650, 660), (720, 730), (790, 800), (860, 870), (930, 940)]\n",
      "done step 3\n"
     ]
    }
   ],
   "source": [
    "# Setting 0.5s Bins\n",
    "bins = np.linspace(0,1200,2400) #<- np.linspace(start, end, steps in between)\n",
    "\n",
    "## If you change only something below this line, you can skip straight to step {Graphing} after.\n",
    "\n",
    "# Light Flashes (for optogenetic/ChR2 experiments), if you are not doing Opto, disregard and run as is\n",
    "lighton = np.arange(300, 940, 70) # where the bars start (start of first pulse, end of last pulse, time between)\n",
    "lightoff = np.arange(310, 950, 70) # where the bars end (end of first pulse, end of last pulse + 10s, time between)\n",
    "# create the dictionary\n",
    "d1 = dict( zip(lighton, lightoff) )\n",
    "# check\n",
    "print(\"d1 = {}\".format(d1))\n",
    "# turn the dictionary into an ITERABLE list of tuples\n",
    "LightPulse = list(d1.items()) \n",
    "print(LightPulse)\n",
    "\n",
    "# Setting viewing range for your graph\n",
    "top = 0.35\n",
    "bottom = 0\n",
    "left = 200\n",
    "right = 580\n",
    "\n",
    "\n",
    "print(\"done step 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Construct filelist from folder path (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_152351/AQ2028_b_n96h20C_300s10x60s_B0702_ak.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_141159/AQ2028_b_n96h20C_300s10x60s_B0702_ab.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_145929/AQ2028_b_n96h20C_300s10x60s_C0702_ai.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_143620/AQ2028_b_n96h20C_300s10x60s_B0702_ae.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_144445/AQ2028_b_n96h20C_300s10x60s_A0702_ad.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H2O/20190702_150846/AQ2028_b_n96h20C_300s10x60s_A0702_ag.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H20_ATR/20190702_143530/AQ2028_ATR_b_n96h20C_300s10x60s_C0702_af.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H20_ATR/20190702_141110/AQ2028_ATR_b_n96h20C_300s10x60s_C0702_ac.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H20_ATR/20190702_142023/AQ2028_ATR_b_n96h20C_300s10x60s_A0702_aa.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H20_ATR/20190702_153220/AQ2028_ATR_b_n96h20C_300s10x60s_A0702_aj.dat', '/Users/Joseph/Desktop/Opto_0702_2019/AQ2028_H20_ATR/20190702_152301/AQ2028_ATR_b_n96h20C_300s10x60s_C0702_al.dat']\n",
      "done step 4\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/Joseph/Desktop/Opto_0702_2019'\n",
    "os.chdir(folder_path) #<- setting your working directory so that your images will be saved here\n",
    "\n",
    "filelist = list() #<- empty list\n",
    "for root, dirs, files in os.walk(folder_path): #<- this for loop goes through your folder \n",
    "    for name in files:\n",
    "        if name.endswith('.dat'): #<- and takes out all files with a .dat (file that contains your data)\n",
    "            filepath = os.path.join(root, name) #<- Notes down the file path of each data file\n",
    "            filelist.append(filepath) #<- saves it into the list\n",
    "    \n",
    "print(filelist)\n",
    "print('done step 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Data Function (No input required, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 5\n"
     ]
    }
   ],
   "source": [
    "def ProcessData(strain, LightPulse): #<- an example of a user-defined function\n",
    "    strain_filelist = []  #<- empty list\n",
    "    for i in filelist: #<- goes through the list and filters for keyword\n",
    "        if strain in i:\n",
    "            strain_filelist.append(i)\n",
    "    Strain_N = len(strain_filelist) #<- N per strain, or number of plates\n",
    "    print(f'This Strain has {Strain_N} plates') #<- prints out number of plates per strain\n",
    "    for i, f in enumerate(strain_filelist, start=1): #<- a progress bar function integrated into data import\n",
    "        N = len(strain_filelist)\n",
    "        statement = f\"Processing {i} of {N} plates\" #<- progress bar statement\n",
    "        DF_Read = pd.read_csv(f, sep=' ', skiprows = 0, header = None) #<- imports and cleans data\n",
    "        if i==1:\n",
    "            DF_Total = DF_Read\n",
    "        else:\n",
    "            DF_Total = pd.concat((DF_Total, DF_Read), ignore_index = False)  #<- imports and cleans data\n",
    "        print(statement)\n",
    "    DF_Total = DF_Total.dropna(axis = 1) #<- more data cleaning\n",
    "    DF_Total = DF_Total.rename( #<- more data cleaning\n",
    "                {0:'time',\n",
    "                1:'speed'}, axis=1)\n",
    "    #0.5s Bins\n",
    "    Bins = [float(i) for i in bins] #<- adds time bins into the data frame\n",
    "    DF_Total['time_bin'] = pd.cut(DF_Total['time'], Bins, labels = Bins[1:])\n",
    "    DF_Speed_DF = DF_Total[[\"time_bin\", \"speed\"]].copy()\n",
    "    \n",
    "    DF_Speed_DF['Pulses'] = 0\n",
    "    \n",
    "    \n",
    "    for Pulse in LightPulse:\n",
    "        Filtered = DF_Speed_DF['time_bin'].between(Pulse[0], Pulse[1], inclusive = True)\n",
    "        print(Filtered)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return{\n",
    "            'N': Strain_N,\n",
    "            'Confirm':DF_Total,\n",
    "            'Speed_DF': DF_Speed_DF, #<- this is the finished product we will use for analysis\n",
    "            'Filelist':strain_filelist} \n",
    "\n",
    "print('done step 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Processing Data (Please Read, Input Here)\n",
    "\n",
    "Here is the hardest part - From your naming convention, you need to pick a unique identifier for each group.\n",
    "\n",
    "This means that all of names of your files for that strain should have that in common but is not commone with across all other files! If you did a good job naming your files and following a good naming convention, this should be easy.\n",
    "\n",
    "## Be careful and really look hard in your naming structure. Note you want an unique identifier in the entire file path for the same group of files. An easy mistake is to have the strain name in the folder name, in this case if you use your strain name as a keyword it would include all files in that folder!\n",
    "\n",
    "For example, if all your N2 files have a certain pattern like \"N2_5x4\" in this following example:\n",
    "'/Users/Joseph/Desktop/AVR14_10sISI_TapHab_0710_2019/N2/20190710_141740/N2_5x4_f94h20c_100s30x10s10s_C0710ab.trv'\n",
    "\n",
    "Then you need to set that identifier for the strain keyword:\n",
    "'Strain_1' = 'N2_5x4'\n",
    "\n",
    "In the same example, if the identifier for your second strain is 'AVR14', then the N2 files will also be included, as this identifier can also be found in this file path.\n",
    "\n",
    "## Depending on how many strains you are running for comparison, you may need to add/delete some lines.\n",
    "\n",
    "You are not naming your data groups here, we have a step for that later.\n",
    "## Here, you want to note down ALL the strains you have in the folder\n",
    "\n",
    "If you have just 2 strains, add hashtags (#) in front of the lines you do not need.\n",
    "If you need more strains, just add more lines, following the same format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 6.1\n"
     ]
    }
   ],
   "source": [
    "#Format: Strain_# = 'unique_identifier'\n",
    "\n",
    "### Make into dictionary\n",
    "StrainNames = {\n",
    "    'Strain_1' : 'AQ2028_b',   #<- each strain will be designated to a unique identifier here\n",
    "    'Strain_2' : 'AQ2028_H2O',\n",
    "    'Strain_3' : '',\n",
    "    'Strain_4' : '',\n",
    "    'Strain_5' : '',\n",
    "    'Strain_6' : '',\n",
    "    'Strain_7' : '',\n",
    "    'Strain_8' : '',\n",
    "    'Strain_9' : '',  #<- empty entries are for those hardcore trackers that tracking this many strains\n",
    "    'Strain_10' : '',\n",
    "    'Strain_11' : '',\n",
    "    'Strain_12' : '',\n",
    "    'Strain_13' : '',\n",
    "    'Strain_14' : '',\n",
    "    'Strain_15' : '',}\n",
    "#...etc, etc\n",
    "\n",
    "print('done step 6.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Process Data (just run this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Strain has 6 plates\n",
      "Processing 1 of 6 plates\n",
      "Processing 2 of 6 plates\n",
      "Processing 3 of 6 plates\n",
      "Processing 4 of 6 plates\n",
      "Processing 5 of 6 plates\n",
      "Processing 6 of 6 plates\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare a Categorical for op __ge__ with a scalar, which is not a category.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3311774620f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStrainNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#<- goes through the dictionary in step 6.1 and processes data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mDataLists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightPulse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Speed_DF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<- appends all data into a list of dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done step 6.2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-8712e6b9c3d8>\u001b[0m in \u001b[0;36mProcessData\u001b[0;34m(strain, LightPulse)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mPulse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLightPulse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mFiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF_Speed_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_bin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetween\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPulse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPulse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclusive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mbetween\u001b[0;34m(self, left, right, inclusive)\u001b[0m\n\u001b[1;32m   4070\u001b[0m         \"\"\"\n\u001b[1;32m   4071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclusive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4072\u001b[0;31m             \u001b[0mlmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4073\u001b[0m             \u001b[0mrmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0;31m# Dispatch to Categorical implementation; pd.CategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;31m# behavior is non-canonical GH#19513\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_to_index_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m             return self._constructor(res_values, index=self.index,\n\u001b[1;32m   1684\u001b[0m                                      name=res_name)\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mdispatch_to_index_op\u001b[0;34m(op, left, right, index_class)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mleft_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNullFrequencyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;31m# DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     msg = (\"Cannot compare a Categorical for op {op} with a \"\n\u001b[1;32m    121\u001b[0m                            \"scalar, which is not a category.\")\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare a Categorical for op __ge__ with a scalar, which is not a category."
     ]
    }
   ],
   "source": [
    "DataLists = [0] #<- generates empty list. 0 is there to account for python's index starting at 0. \n",
    "# we want indexing to start at 1 (when I say #1 I want the first point, not the second point)\n",
    "\n",
    "for s in StrainNames.values(): #<- goes through the dictionary in step 6.1 and processes data\n",
    "    if not s == '':\n",
    "        DataLists.append(ProcessData(s, LightPulse)['Speed_DF']) #<- appends all data into a list of dataframes\n",
    "\n",
    "print('done step 6.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Grouping Data and Naming (Optional: Add input here)\n",
    "\n",
    "Here, you get to name your data groups/strain! Name your groups however you like under between the quotation marks for each strain.\n",
    "\n",
    "For example: If your Strain1 is N2 and you wish for the group to be called N2,\n",
    "your line should look like:\n",
    "\n",
    "DataLists[x].assign(dataset = 'N2')\n",
    "\n",
    "## Go back to step 6.1 to check which strain is which item on the DataLists.\n",
    "In this example, the first item on DataLists is AQ2028_b.\n",
    "\n",
    "\n",
    "## Remember: Put your name in quotes. (ex: 'N2' and not N2)\n",
    "\n",
    "As default, the names are set to the unique identifier labels.\n",
    "\n",
    "## Depending on the number of strains you are running the comparison, you may have to delete/add lines of code (following the same format). \n",
    "## Remember to add/delete commas too.\n",
    "\n",
    "# If you want to change your groups, you do that here. \n",
    "For example, if you have 5 strains in your folder but only want to compare between 2 or 3 strains, designate that here and follow through with steps 6 and 7. Once you are done, come back to step 6 and change your groups again (You are going to have to change your graph titles for the second run-through though)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time_bin   speed  Pulses     dataset\n",
      "0         0.500208  0.0000       0    AQ2028_b\n",
      "1         0.500208  0.0000       0    AQ2028_b\n",
      "2         0.500208  0.0000       0    AQ2028_b\n",
      "3         0.500208  0.0000       0    AQ2028_b\n",
      "4         0.500208  0.0000       0    AQ2028_b\n",
      "5         0.500208  0.0000       0    AQ2028_b\n",
      "6         1.000417  0.0000       0    AQ2028_b\n",
      "7         1.000417  0.0000       0    AQ2028_b\n",
      "8         1.000417  0.0000       0    AQ2028_b\n",
      "9         1.000417  0.0000       0    AQ2028_b\n",
      "10        1.500625  0.0000       0    AQ2028_b\n",
      "11        1.500625  0.0000       0    AQ2028_b\n",
      "12        1.500625  0.0000       0    AQ2028_b\n",
      "13        1.500625  0.0000       0    AQ2028_b\n",
      "14        2.000834  0.0000       0    AQ2028_b\n",
      "15        2.000834  0.0000       0    AQ2028_b\n",
      "16        2.000834  0.0000       0    AQ2028_b\n",
      "17        2.000834  0.0000       0    AQ2028_b\n",
      "18        2.501042  0.0000       0    AQ2028_b\n",
      "19        2.501042  0.0000       0    AQ2028_b\n",
      "20        2.501042  0.0000       0    AQ2028_b\n",
      "21        2.501042  0.0000       0    AQ2028_b\n",
      "22        2.501042  0.0000       0    AQ2028_b\n",
      "23        3.001251  0.0000       0    AQ2028_b\n",
      "24        3.001251  0.0000       0    AQ2028_b\n",
      "25        3.001251  0.0000       0    AQ2028_b\n",
      "26        3.001251  0.0000       0    AQ2028_b\n",
      "27        3.001251  0.0000       0    AQ2028_b\n",
      "28        3.001251  0.0000       0    AQ2028_b\n",
      "29        3.001251  0.0000       0    AQ2028_b\n",
      "...            ...     ...     ...         ...\n",
      "28658  1198.999583  0.2245       0  AQ2028_H2O\n",
      "28659  1198.999583  0.2206       0  AQ2028_H2O\n",
      "28660  1198.999583  0.2104       0  AQ2028_H2O\n",
      "28661  1199.499792  0.2038       0  AQ2028_H2O\n",
      "28662  1199.499792  0.2041       0  AQ2028_H2O\n",
      "28663  1199.499792  0.2124       0  AQ2028_H2O\n",
      "28664  1199.499792  0.2218       0  AQ2028_H2O\n",
      "28665  1199.499792  0.2093       0  AQ2028_H2O\n",
      "28666  1199.499792  0.1886       0  AQ2028_H2O\n",
      "28667  1199.499792  0.2051       0  AQ2028_H2O\n",
      "28668  1199.499792  0.2059       0  AQ2028_H2O\n",
      "28669  1199.499792  0.2017       0  AQ2028_H2O\n",
      "28670  1199.499792  0.2195       0  AQ2028_H2O\n",
      "28671  1199.499792  0.2347       0  AQ2028_H2O\n",
      "28672  1199.499792  0.2306       0  AQ2028_H2O\n",
      "28673  1199.499792  0.2232       0  AQ2028_H2O\n",
      "28674  1200.000000  0.2268       0  AQ2028_H2O\n",
      "28675  1200.000000  0.2153       0  AQ2028_H2O\n",
      "28676  1200.000000  0.2068       0  AQ2028_H2O\n",
      "28677  1200.000000  0.2095       0  AQ2028_H2O\n",
      "28678  1200.000000  0.2104       0  AQ2028_H2O\n",
      "28679  1200.000000  0.2111       0  AQ2028_H2O\n",
      "28680  1200.000000  0.2104       0  AQ2028_H2O\n",
      "28681  1200.000000  0.2065       0  AQ2028_H2O\n",
      "28682  1200.000000  0.2013       0  AQ2028_H2O\n",
      "28683  1200.000000  0.2061       0  AQ2028_H2O\n",
      "28684  1200.000000  0.2123       0  AQ2028_H2O\n",
      "28685  1200.000000  0.0000       0  AQ2028_H2O\n",
      "28686          NaN  0.0000       0  AQ2028_H2O\n",
      "28687          NaN  0.0000       0  AQ2028_H2O\n",
      "\n",
      "[254136 rows x 4 columns]\n",
      "done step 7\n"
     ]
    }
   ],
   "source": [
    "#to add a line, add a comma to the last line and press 'enter' to type into a new line\n",
    "TotalConcatenated = pd.concat([DataLists[1].assign(dataset = StrainNames.get(\"Strain_1\")),\n",
    "                               DataLists[2].assign(dataset = StrainNames.get(\"Strain_2\"))\n",
    "                              ])\n",
    "print(TotalConcatenated)\n",
    "print('done step 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1 Graphing with Light Pulses (Skip to 7.2 if you are not using ChR2)\n",
    "\n",
    "## Here, feel free to change the graph title and axis labels! Images are automatically saved in your folder with your data.\n",
    "\n",
    "# Here, you may need to be patient - this code goes through millions of rows of data to plot your graph, so it may take a minute (or two.... or more...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(linewidth = 2.5)#<- Make your figure lines THICCCC for clean display (posters)\n",
    "plt.figure(figsize=(12,7))#<- set your figure size (width, length)\n",
    "plt.gca().xaxis.grid(False)#<- gets rid of x-axis markers to make data look clean \n",
    "for tuple in d2:\n",
    "    print(\"Creating bar: {}-{}\".format(tuple[0], tuple[1]))\n",
    "    plt.axvspan(xmin=tuple[0], xmax=tuple[1], facecolor=\"#CCFFFF\", alpha=0.2) # alpha controls how transparent the bars are  #<- the blue bars indicating light pulse\n",
    "ax = sns.lineplot(x=\"time_bin\", #<- Here we use seaborn as our graphing package. \n",
    "             y=\"speed\", \n",
    "             data = TotalConcatenated,\n",
    "             hue = 'dataset', #<- Here we use the extra column from step 6 to separate by group\n",
    "             palette = 'deep')#<- Change colour palette here if you like\n",
    "plt.xlabel(\"Time (s)\")#<- X-axis title\n",
    "plt.ylabel(\"Speed (mm/s)\")#<- Y-Axis title\n",
    "plt.title(\"Speed Trace\")#<- Figure Title\n",
    "plt.ylim(top = top) #<- setting the viewing range, from previous input in step 2\n",
    "plt.ylim(bottom = bottom)\n",
    "plt.xlim(left= left)\n",
    "plt.xlim(right = right)\n",
    "ax.legend(loc = 'upper right', fontsize = '13') #<- location of your legend\n",
    "plt.savefig(f'Speed_Trace_{left}to{right}s.png', format='png', dpi=900) #<- saves the figure to a tif file\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Graphing without Light Pulse (Run this if you dont use ChR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(linewidth = 2.5)\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.gca().xaxis.grid(False)\n",
    "ax = sns.lineplot(x=\"time_bin\", \n",
    "             y=\"speed\", \n",
    "             data = TotalConcatenated,\n",
    "             hue = 'dataset',\n",
    "             palette = 'deep')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Speed (mm/s)\")\n",
    "plt.title(\"Speed Trace\")\n",
    "plt.ylim(top = top)\n",
    "plt.ylim(bottom = bottom)\n",
    "plt.xlim(left= left)\n",
    "plt.xlim(right = right)\n",
    "ax.legend(loc = 'upper right', fontsize = '13')\n",
    "plt.savefig(f'Speed_Trace_{left}to{right}s.png', format='png', dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
